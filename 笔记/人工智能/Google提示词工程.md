以下是文章《Prompt Engineering》的核心内容提炼：

---

### **一、提示工程基础**

1. **定义**

- 提示工程是设计高质量提示的过程，用于引导大语言模型（LLM）生成准确输出。

- 提示需考虑模型选择、训练数据、配置参数、措辞风格、结构和上下文等因素。

2. **LLM输出配置**

- **输出长度**：限制生成令牌数量可降低计算成本，但需通过提示设计确保简洁性。

- **采样控制**：

- **温度（Temperature）**：控制随机性（低温度→确定性高；高温度→创造性高）。

- **Top-K/Top-P**：筛选高概率令牌（Top-K限制候选数；Top-P限制累积概率）。

- **参数组合策略**：极端值会覆盖其他设置（如温度=0时忽略Top-K/Top-P）。

---

### **二、核心提示技术**

1. **基础技术**

- **零样本（Zero-Shot）**：仅提供任务描述（无示例）。

- **单样本/少样本（One-Shot/Few-Shot）**：提供1个/多个示例引导模型模仿模式。

- **系统提示（System Prompting）**：定义任务全局规则（如输出格式为JSON）。

- **角色提示（Role Prompting）**：赋予模型特定身份（如“旅行向导”）。

- **上下文提示（Contextual Prompting）**：提供任务相关背景信息（如博客主题）。

2. **进阶推理技术**

- **链式思考（Chain of Thought, CoT）**：要求模型分步推理（尤其适用于数学/逻辑问题）。

- **自我一致性（Self-Consistency）**：多次采样不同推理路径，投票选择高频答案。

- **思维树（Tree of Thoughts, ToT）**：并行探索多推理路径（优于单一路径的CoT）。

- **ReAct（Reason & Act）**：结合推理与外部工具调用（如搜索API获取实时信息）。

- **退步提示（Step-Back Prompting）**：先回答抽象问题，再解决具体任务（激活背景知识）。

3. **自动化与代码相关**

- **自动提示工程（APE）**：用LLM生成并优化提示。

- **代码提示**：

- 生成代码（如Bash/Python脚本）。

- 解释代码逻辑。

- 跨语言代码翻译（如Bash→Python）。

- 调试与代码审查。

---

### **三、最佳实践**

1. **提示设计原则**

- **提供示例**：少样本提示显著提升准确性。

- **简洁明确**：避免冗余信息，使用指令性动词（如“生成”“分类”）。

- **输出控制**：指定格式（如JSON）、长度或样式。

- **变量化**：动态替换关键字段（如 {city} ）提升复用性。

- **正向指令优先**：明确“要做什么”而非“不要做什么”。

2. **工程优化**

- **分类任务**：少样本示例需覆盖所有类别并随机排序。

- **结构化输出**：用JSON/XML减少幻觉，方便解析（需注意令牌消耗和截断问题）。

- **模型适配**：跟踪模型更新并调整提示。

- **协作与文档**：

- 团队协作测试不同提示。

- 完整记录提示版本、参数和输出（推荐表格模板）。

- 保存提示至独立文件，便于维护。

3. **CoT专用建议**

- 答案需置于推理步骤后。

- 温度设为0（确保确定性）。

- 从输出中分离最终答案。

---

### **四、关键挑战**

- **重复循环问题**：不当的温度/Top-K/P设置导致模型陷入重复输出循环。

- **数学推理缺陷**：LLM需依赖CoT等技术解决基础计算问题。

- **多模态提示**：文本为主，其他模态（如图像）需模型额外支持。

---

### **五、总结**

提示工程是迭代过程，需结合技术选择（如CoT/ReAct）、参数调优（温度/Top-K）和严格实践（示例/文档）。通过系统化方法，可显著提升LLM输出的准确性、效率及可控性。